{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Onur Can \n# Project is done for Prof. Mehmet Gönen's DASC 521: Introduction to Machine Learning @ Koç University MSc Data Science Program\n# Thanks Prof Mehmet for the dataset generation and instructions\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport math as math","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:43:51.584634Z","iopub.execute_input":"2022-06-04T07:43:51.585371Z","iopub.status.idle":"2022-06-04T07:43:51.593734Z","shell.execute_reply.started":"2022-06-04T07:43:51.585331Z","shell.execute_reply":"2022-06-04T07:43:51.592593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting data into memory\ndata_set = np.genfromtxt(\"../input/sample-clothing-images-for-classification/hw02_images.csv\", delimiter = \",\").astype(int)\nlabels = np.genfromtxt(\"../input/sample-clothing-images-for-classification/hw02_labels.csv\").astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:43:51.59553Z","iopub.execute_input":"2022-06-04T07:43:51.59589Z","iopub.status.idle":"2022-06-04T07:44:31.912247Z","shell.execute_reply.started":"2022-06-04T07:43:51.595861Z","shell.execute_reply":"2022-06-04T07:44:31.911584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Initilization of the data\ntraining_images = data_set[0:30000,:]   #traning data set\ntest_images = data_set[30000:35000,:]   #test data set\nK = np.max(labels)                      #number of classes\nN = training_images.shape[0]            #data sample count\nd = training_images.shape[1]            #number of features\n\nprint(data_set)\nprint(labels.shape,labels.size)\nprint(data_set.shape,training_images.shape,test_images.shape)\nprint(K,N,d)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:44:31.91363Z","iopub.execute_input":"2022-06-04T07:44:31.914433Z","iopub.status.idle":"2022-06-04T07:44:31.923627Z","shell.execute_reply.started":"2022-06-04T07:44:31.9144Z","shell.execute_reply":"2022-06-04T07:44:31.922714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Parameter estimation for training data set\n#Sample mean & standart deviation calculations for xi 1-784 and for classes 1-5\n\nsample_means = np.zeros((K,d), dtype=float)\nsample_stdevs = np.zeros((K,d), dtype=float)\nclass_priors = np.zeros(K, dtype=float)\n\nfor i in range (K):\n    current_class_set = training_images[labels[0:30000] == (i+1)]\n    print(\"Shape of data class = \", i+1,\"is equal to \",current_class_set.shape)\n    class_priors[i] = current_class_set.shape[0] / N\n    for j in range (d):\n        feature_mean = np.mean(current_class_set[:,j])  #for class i feature j\n        feature_stdev = np.std(current_class_set[:,j])  #for class i feature j\n        sample_means[i][j] = feature_mean\n        sample_stdevs[i][j] = feature_stdev\n\nprint(\"\\nSample_means are listed below with the shape of the matrix\\n\")        \nprint(sample_means)\nprint(sample_means.shape)\nprint(\"\\nSample_standart deviations are listed below with the shape of the matrix\\n\")        \nprint(sample_stdevs)\nprint(sample_stdevs.shape)\nprint(\"\\nClass priors are listed below\\n\")\nprint(class_priors)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:44:31.92471Z","iopub.execute_input":"2022-06-04T07:44:31.92553Z","iopub.status.idle":"2022-06-04T07:44:32.409695Z","shell.execute_reply.started":"2022-06-04T07:44:31.9255Z","shell.execute_reply":"2022-06-04T07:44:32.408625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate score functions\n#for continuous naive bayes - gaussian - via Sum of  individual likelihoods\n\ndef sum_x_i_likelihoods(X,mean,stdeviation,dimension,Klass):      #sum of individual Likelihoods\n    xi_individual_likelihoods = np.zeros(dimension)\n    for i in range (0,dimension):\n        L = (-0.5) * np.log(2 * math.pi * stdeviation[Klass][i]**2) - (0.5) * (\n            X[0][i] - mean[Klass][i])**2 / stdeviation[Klass][i]**2\n        xi_individual_likelihoods[i] = L\n    sum_of_L = np.sum(xi_individual_likelihoods)\n    return sum_of_L\n\n#Score values for classes\ndef class_score(K,training_set,mean_set,deviation_set,d,priors):  # gx = sum(log(likelihoods) + log(prior) for each x\n    score_array = np.zeros(5)\n    for j in range(K):\n        score_array[j] = sum_x_i_likelihoods(training_set,mean_set,deviation_set,d,j) + np.log(priors[j])\n    return score_array\n\nscore_matrix = np.zeros((N,5))\nfor k in range(N):\n    score_matrix[k] = (class_score(K,training_images[k,None],sample_means,sample_stdevs,d,class_priors))\nprint(score_matrix,score_matrix.shape)\n    \n    \n\n#print(class_score(K,training_images[0,None],sample_means,sample_stdevs,d,class_priors))\n#print(sum_x_i_likelihoods(training_images[0,None],sample_means[0,None],sample_stdevs[0,None],d,0))","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:44:32.41206Z","iopub.execute_input":"2022-06-04T07:44:32.412497Z","iopub.status.idle":"2022-06-04T07:56:01.228365Z","shell.execute_reply.started":"2022-06-04T07:44:32.412456Z","shell.execute_reply":"2022-06-04T07:56:01.227408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Score Values for the Test Values\nN_test = test_images.shape[0]            #test data sample count\ntest_score_matrix = np.zeros((N_test,5))\nfor k in range(N_test):\n    test_score_matrix[k] = (class_score(K,test_images[k,None],sample_means,sample_stdevs,d,class_priors))\nprint(test_score_matrix,test_score_matrix.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:56:01.229868Z","iopub.execute_input":"2022-06-04T07:56:01.230189Z","iopub.status.idle":"2022-06-04T07:57:55.840836Z","shell.execute_reply.started":"2022-06-04T07:56:01.230162Z","shell.execute_reply":"2022-06-04T07:57:55.83984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CONFUSION MATRIX for training data set\ny_predicted_training = np.zeros(N).astype(int)\n\ntraning_labels = labels[0:30000]\n\n\nfor h in range(N):\n    b = np.max(score_matrix[h])\n    c = (score_matrix[h] == b)\n    for g in range(5):\n          if c[g] == True:\n            y_predicted_training[h] = g + 1\n            break\nprint(y_predicted_training.shape)\n\nconfusion_matrix = pd.crosstab(y_predicted_training, traning_labels, rownames = ['y_pred'], colnames = ['y_truth'])    #PANDAS\nprint(confusion_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:57:55.842785Z","iopub.execute_input":"2022-06-04T07:57:55.843212Z","iopub.status.idle":"2022-06-04T07:57:56.197598Z","shell.execute_reply.started":"2022-06-04T07:57:55.843173Z","shell.execute_reply":"2022-06-04T07:57:56.196561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CONFUSION MATRIX for test data set\ny_predicted_test = np.zeros(N_test).astype(int)\n\ntest_labels = labels[30000:35000]\n\n\nfor h in range(N_test):\n    b = np.max(test_score_matrix[h])\n    c = (test_score_matrix[h] == b)\n    for g in range(5):\n          if c[g] == True:\n            y_predicted_test[h] = g + 1\n            break\nprint(y_predicted_test.shape)\n\nconfusion_matrix = pd.crosstab(y_predicted_test, test_labels, rownames = ['y_pred'], colnames = ['y_truth'])    #PANDAS\nprint(confusion_matrix)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:57:56.198761Z","iopub.execute_input":"2022-06-04T07:57:56.19915Z","iopub.status.idle":"2022-06-04T07:57:56.274548Z","shell.execute_reply.started":"2022-06-04T07:57:56.199118Z","shell.execute_reply":"2022-06-04T07:57:56.273846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}