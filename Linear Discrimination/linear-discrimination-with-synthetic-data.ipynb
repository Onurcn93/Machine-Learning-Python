{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Onur Can \n# Project is done for Prof. Mehmet Gönen's DASC 521: Introduction to Machine Learning @ Koç University MSc Data Science Program\n# Thanks Prof Mehmet for the dataset generation and instructions\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndef safelog (x):\n    return(np.log(x + 1e-100))","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:58:43.203225Z","iopub.execute_input":"2022-06-05T14:58:43.203945Z","iopub.status.idle":"2022-06-05T14:58:43.209730Z","shell.execute_reply.started":"2022-06-05T14:58:43.203901Z","shell.execute_reply":"2022-06-05T14:58:43.208744Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Parameters","metadata":{}},{"cell_type":"code","source":"#random seed 421 to generate data point\nnp.random.seed(666)\n#mean parameters for synthetic data\nclass_means = np.array([[+0.0, +2.5],\n                        [-2.5, -2.0],\n                        [+2.5, -2.0]])\nprint(class_means)\n#covariance parameters for synthetic data\nclass_covariances = np.array([[[+3.2 , +0.0],\n                               [+0.0, +1.2]],\n                              [[+1.2, +0.8],\n                               [0.8, +1.2]],\n                              [[+1.2, -0.8],\n                               [-0.8, +1.2]]])\nprint(class_covariances)\nclass_sizes = np.array([120, 80, 100])\nprint(class_sizes)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:58:43.221418Z","iopub.execute_input":"2022-06-05T14:58:43.222211Z","iopub.status.idle":"2022-06-05T14:58:43.231467Z","shell.execute_reply.started":"2022-06-05T14:58:43.222165Z","shell.execute_reply":"2022-06-05T14:58:43.230552Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Data Generation","metadata":{}},{"cell_type":"code","source":"#generate random samples with seed 421\nnp.random.seed(666)\n\npoints1 = np.random.multivariate_normal(class_means[0,:], class_covariances[0,:,:], class_sizes[0]) # Red\npoints2 = np.random.multivariate_normal(class_means[1,:], class_covariances[1,:,:], class_sizes[1]) # Green\npoints3 = np.random.multivariate_normal(class_means[2,:], class_covariances[2,:,:], class_sizes[2]) # Blue\nX = np.vstack((points1, points2, points3))\n\n#Generate corresponding labels\ny = np.concatenate((np.repeat(1, class_sizes[0]), np.repeat(2, class_sizes[1]), np.repeat(3, class_sizes[2]))).astype(int)\nprint(y,y.shape)\nprint(X.shape)\n\n#number of classes and number of samples\nN = X.shape[0]\nK = np.max(y)\nprint(N, K)\n\n# one-of-K encoding\nY_truth = np.zeros((N, K)).astype(int)\nY_truth[range(N), y - 1] = 1\n#print(Y_truth)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:58:43.239256Z","iopub.execute_input":"2022-06-05T14:58:43.240292Z","iopub.status.idle":"2022-06-05T14:58:43.253227Z","shell.execute_reply.started":"2022-06-05T14:58:43.240257Z","shell.execute_reply":"2022-06-05T14:58:43.252524Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Plotting Training Data","metadata":{}},{"cell_type":"code","source":"#plotting operations to visualize initial data\nplt.figure( figsize = (6,6))\nplt.plot(points1[:,0],points1[:,1],\"r.\",markersize = 10)\nplt.plot(points2[:,0],points2[:,1],\"g.\",markersize = 10)\nplt.plot(points3[:,0],points3[:,1],\"b.\",markersize = 10)\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:58:43.254965Z","iopub.execute_input":"2022-06-05T14:58:43.255269Z","iopub.status.idle":"2022-06-05T14:58:43.454594Z","shell.execute_reply.started":"2022-06-05T14:58:43.255241Z","shell.execute_reply":"2022-06-05T14:58:43.453579Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Algorithm Parameters","metadata":{}},{"cell_type":"code","source":"#set learning parameters\neta = 0.01 #step size \nepsilon = 0.001 #if change in parameter smaller than epsilon stop","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:58:43.456280Z","iopub.execute_input":"2022-06-05T14:58:43.456651Z","iopub.status.idle":"2022-06-05T14:58:43.460681Z","shell.execute_reply.started":"2022-06-05T14:58:43.456618Z","shell.execute_reply":"2022-06-05T14:58:43.459921Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Parameter Initialization","metadata":{}},{"cell_type":"code","source":"#randomly select W and w0\nnp.random.seed(666)\nW = np.random.uniform(low = -0.01, high = +0.01, size = (X.shape[1], K))\nw0 = np.random.uniform(low = -0.01, high = +0.01, size = (1, K))\n\nprint(W,W.shape,w0,w0.shape)\n#print(np.vstack((W, w0)))    # to be used in matrix multiplication\n#print(np.hstack((X,np.ones((N,1))))) # to be used in matrix multiplication","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:58:43.461985Z","iopub.execute_input":"2022-06-05T14:58:43.462414Z","iopub.status.idle":"2022-06-05T14:58:43.475682Z","shell.execute_reply.started":"2022-06-05T14:58:43.462384Z","shell.execute_reply":"2022-06-05T14:58:43.475012Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## Sigmoid Function\n\n$\\textrm{sigmoid}(\\boldsymbol{w}^{\\top} \\boldsymbol{x} + w_{0}) = \\dfrac{1}{1 + \\exp\\left[-(\\boldsymbol{w}^{\\top} \\boldsymbol{x} + w_{0})\\right]}$","metadata":{}},{"cell_type":"code","source":"#define sigmoid function\ndef sigmoid(X, W, w0):\n    scores = 1 / (1 + np.exp(-(np.matmul(X, W) + w0)))     #w.t * x = x * w\n    #scores = np.amax(scores,axis = 1, keepdims = True)\n    return(scores)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:58:43.477140Z","iopub.execute_input":"2022-06-05T14:58:43.477777Z","iopub.status.idle":"2022-06-05T14:58:43.492633Z","shell.execute_reply.started":"2022-06-05T14:58:43.477742Z","shell.execute_reply":"2022-06-05T14:58:43.491799Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Estimated Gradient Functions\n","metadata":{}},{"cell_type":"markdown","source":"\\begin{align*}\n\\dfrac{\\partial \\textrm{Error}}{\\partial \\boldsymbol{w}_{c}} &= \\sum\\limits_{i = 1}^{N} (y_{ic} - \\widehat{y}_{ic})*\\widehat{y}_{ic}*(1 - \\widehat{y}_{ic})\\boldsymbol{x}_{i} \\\\\n\\dfrac{\\partial \\textrm{Error}}{\\partial w_{c0}} &= \\sum\\limits_{i = 1}^{N} (y_{ic} - \\widehat{y}_{ic})*\\widehat{y}_{ic}*(1 - \\widehat{y}_{ic}) \\\\\n\\end{align*}\n","metadata":{}},{"cell_type":"code","source":"# define the gradient functions\n# Y TRUTH is a matrix\n#\ndef gradient_W(X, Y_truth, Y_predicted):\n    return(np.asarray([np.matmul(((Y_truth[:,c] - Y_predicted[:,c])* Y_predicted[:,c]) * (1 - Y_predicted[:,c]), X)\n                                  for c in range(K)]).transpose())\n\ndef gradient_w0(Y_truth, Y_predicted):\n    return(np.sum((Y_truth - Y_predicted)*(Y_predicted)*( 1 - Y_predicted), axis = 0))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:58:43.493728Z","iopub.execute_input":"2022-06-05T14:58:43.494134Z","iopub.status.idle":"2022-06-05T14:58:43.506938Z","shell.execute_reply.started":"2022-06-05T14:58:43.494105Z","shell.execute_reply":"2022-06-05T14:58:43.505955Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# learn W and w0 using gradient descent\niteration = 1\nobjective_values = []\nwhile 1:\n    Y_predicted = sigmoid(X, W, w0)\n\n    objective_values = np.append(objective_values, -np.sum(Y_truth * safelog(Y_predicted)))\n    W_old = W\n    w0_old = w0\n\n    W = W + eta * gradient_W(X, Y_truth, Y_predicted)\n    w0 = w0 + eta * gradient_w0(Y_truth, Y_predicted)\n\n    if np.sqrt(np.sum((w0 - w0_old))**2 + np.sum((W - W_old)**2)) < epsilon:\n        break\n        \n    iteration = iteration + 1\nprint(W)\nprint(w0)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:58:43.508838Z","iopub.execute_input":"2022-06-05T14:58:43.509334Z","iopub.status.idle":"2022-06-05T14:58:43.835064Z","shell.execute_reply.started":"2022-06-05T14:58:43.509300Z","shell.execute_reply":"2022-06-05T14:58:43.834062Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Convergence","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 6))\nplt.plot(range(1, iteration + 1), objective_values, \"k-\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Error\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:58:43.836570Z","iopub.execute_input":"2022-06-05T14:58:43.837355Z","iopub.status.idle":"2022-06-05T14:58:44.012703Z","shell.execute_reply.started":"2022-06-05T14:58:43.837315Z","shell.execute_reply":"2022-06-05T14:58:44.011733Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"## Training Performance","metadata":{}},{"cell_type":"code","source":"# calculate confusion matrix\ny_predicted = np.argmax(Y_predicted, axis = 1) + 1\nconfusion_matrix = pd.crosstab(y_predicted, y, rownames = ['y_pred'], colnames = ['y_truth'])\nprint(confusion_matrix)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:58:44.014155Z","iopub.execute_input":"2022-06-05T14:58:44.014919Z","iopub.status.idle":"2022-06-05T14:58:44.035932Z","shell.execute_reply.started":"2022-06-05T14:58:44.014877Z","shell.execute_reply":"2022-06-05T14:58:44.035025Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Visualization","metadata":{}},{"cell_type":"code","source":"# evaluate discriminant function on a grid\nx1_interval = np.linspace(-8, +8, 1201)\nx2_interval = np.linspace(-8, +8, 1201)\nx1_grid, x2_grid = np.meshgrid(x1_interval, x2_interval)\ndiscriminant_values = np.zeros((len(x1_interval), len(x2_interval), K))\nfor c in range(K):\n    discriminant_values[:,:,c] = W[0, c] * x1_grid + W[1, c] * x2_grid + w0[0, c]\n\nA = discriminant_values[:,:,0]\nB = discriminant_values[:,:,1]\nC = discriminant_values[:,:,2]\nA[(A < B) & (A < C)] = np.nan\nB[(B < A) & (B < C)] = np.nan\nC[(C < A) & (C < B)] = np.nan\ndiscriminant_values[:,:,0] = A\ndiscriminant_values[:,:,1] = B\ndiscriminant_values[:,:,2] = C\n\nplt.figure(figsize = (10, 10))\nplt.plot(X[y == 1, 0], X[y  == 1, 1], \"r.\", markersize = 10)\nplt.plot(X[y  == 2, 0], X[y  == 2, 1], \"g.\", markersize = 10)\nplt.plot(X[y  == 3, 0], X[y  == 3, 1], \"b.\", markersize = 10)\nplt.plot(X[y_predicted != y , 0], X[y_predicted != y , 1], \"ko\", markersize = 12, fillstyle = \"none\")\nplt.contour(x1_grid, x2_grid, discriminant_values[:,:,0] - discriminant_values[:,:,1], levels = 0, colors = \"k\")\nplt.contour(x1_grid, x2_grid, discriminant_values[:,:,0] - discriminant_values[:,:,2], levels = 0, colors = \"k\")\nplt.contour(x1_grid, x2_grid, discriminant_values[:,:,1] - discriminant_values[:,:,2], levels = 0, colors = \"k\")\nplt.xlabel(\"$x_1$\")\nplt.ylabel(\"$x_2$\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:58:44.037256Z","iopub.execute_input":"2022-06-05T14:58:44.037938Z","iopub.status.idle":"2022-06-05T14:58:44.654685Z","shell.execute_reply.started":"2022-06-05T14:58:44.037906Z","shell.execute_reply":"2022-06-05T14:58:44.653760Z"},"trusted":true},"execution_count":36,"outputs":[]}]}